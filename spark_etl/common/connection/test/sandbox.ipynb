{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "val = \"varchar\"\n",
    "z = re.match(r\"(\\w+)(?=\\(([0-9]{1,4})\\))?\",val)\n",
    "print(z.groups())\n",
    "\n",
    "val = \"decimal(20,4)\"\n",
    "z = re.match(r\"(\\w+)(?=\\(([0-9]{1,2},[0-9]{1,2})\\))\",val)\n",
    "print(z.groups())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "MODULE_FULL_PATH = 'd:/GitHUB_Sandbox'\n",
    "\n",
    "sys.path.insert(1, MODULE_FULL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import types\n",
    "from sandbox.spark_etl.common.data_validator.dtype_mapper_hive import dtypes_mapper_hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_translation = dtypes_mapper_hive()\n",
    "print(dict_translation.translate_dtype_to_sparkdtype(raw_dtype=\"varchar(10)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from json import loads\n",
    "from sandbox.spark_etl.common.data_validator.source_schema import source_schema\n",
    "from sandbox.spark_etl.common.data_validator.dtype_mapper_hive import dtypes_mapper_hive\n",
    "\n",
    "\n",
    "def format_output_to_list_of_dict(output_json : dict) -> dict:\n",
    "    \n",
    "    for field_md in output_json[\"fields\"]:\n",
    "        print(field_md)\n",
    "        \n",
    "    # {\"fields\":[{\"metadata\":{\"datatype_precision\":\"10\",\"datatype_scale\":null,\"format\":\"\",\"source_datatype\":\"varchar(10)\",\"spark_datatype\":\"string\"},\"name\":\"COLUMN_1\",\"nullable\":false,\"type\":\"string\"},{\"metadata\":{\"datatype_precision\":\"10\",\"datatype_scale\":\"4\",\"format\":\"\",\"source_datatype\":\"decimal(10,4)\",\"spark_datatype\":\"decimal(10,4)\"},\"name\":\"COLUMN_2\",\"nullable\":true,\"type\":\"decimal(10,4)\"},{\"metadata\":{\"datatype_precision\":null,\"datatype_scale\":null,\"format\":\"\",\"source_datatype\":\"timestamp\",\"spark_datatype\":\"timestamp\"},\"name\":\"COLUMN_2\",\"nullable\":true,\"type\":\"timestamp\"}],\"type\":\"struct\"}\n",
    "\n",
    "raw_schema_MD = [\n",
    "            {\n",
    "            \"column_name\" : \"COLUMN_1\",\n",
    "            \"required\" : True,\n",
    "            \"data_type\" : \"varchar(10)\",\n",
    "            \"format\" : \"\"\n",
    "            }\n",
    "            ,\n",
    "            {\n",
    "                \"column_name\" : \"COLUMN_2\",\n",
    "                \"required\" : False,\n",
    "                \"data_type\" : \"decimal(10,4)\",\n",
    "                \"format\" : \"\"\n",
    "            },\n",
    "            {\n",
    "                \"column_name\" : \"COLUMN_2\",\n",
    "                \"required\" : False,\n",
    "                \"data_type\" : \"timestamp\",\n",
    "                \"format\" : \"\"\n",
    "            }        \n",
    "        ]\n",
    "# {\"fields\":[{\"metadata\":{\"datatype_precision\":\"10\",\"datatype_scale\":null,\"format\":\"\",\"source_datatype\":\"varchar(10)\",\"spark_datatype\":\"string\"},\"name\":\"COLUMN_1\",\"nullable\":false,\"type\":\"string\"}\n",
    "#            ,{\"metadata\":{\"datatype_precision\":\"10\",\"datatype_scale\":\"4\",\"format\":\"\",\"source_datatype\":\"decimal(10,4)\",\"spark_datatype\":\"decimal(10,4)\"},\"name\":\"COLUMN_2\",\"nullable\":true,\"type\":\"decimal(10,4)\"}]\n",
    "#  ,\"type\":\"struct\"}\n",
    "schema_extended = source_schema(list_of_dict=raw_schema_MD,dtype_translator=dtypes_mapper_hive()).get_struct_schema_with_sparkdtypes()\n",
    "# print(\"HEY\",schema_extended.json()  )\n",
    "print(\"HEY\",format_output_to_list_of_dict ( loads(schema_extended.json() ) ) )\n",
    "\n",
    "result = [ {'metadata': {'datatype_precision': '10', 'datatype_scale': None, 'format': '', 'source_datatype': 'varchar(10)', 'spark_datatype': 'string'}, 'name': 'COLUMN_1', 'nullable': False, 'type': 'string'},\n",
    "{'metadata': {'datatype_precision': '10', 'datatype_scale': '4', 'format': '', 'source_datatype': 'decimal(10,4)', 'spark_datatype': 'decimal(10,4)'}, 'name': 'COLUMN_2', 'nullable': True, 'type': 'decimal(10,4)'},\n",
    "{'metadata': {'datatype_precision': None, 'datatype_scale': None, 'format': '', 'source_datatype': 'timestamp', 'spark_datatype': 'timestamp'}, 'name': 'COLUMN_2', 'nullable': True, 'type': 'timestamp'}\n",
    "]\n",
    "\n",
    "pairs = zip (result,loads(schema_extended.json() ) )\n",
    "            \n",
    "any( expected_val !=  result_val for expected_val,result_val in pairs )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed6e3d2f1dfeb78c40517b049f5ad46a20c2ea8d4a696d687d19c92f25406a76"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('python_etl_utils': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
